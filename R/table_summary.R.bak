source('misc.R')

#' Compute Basic Column Statistics Inside Aster
#' 
#' Computes statistics for all table attributes (columns)
#' Value is based on RODBC sqlColumns table with additional columns
#' for computed statistics.
#' 
#' @export
#' 
getTableSummary <- function (channel, tableName, include=NULL, except=NULL, where=NULL, collect.mode=FALSE) {
  table_info = sqlColumns(channel, tableName)
  
  table_info = includeExcludeColumns(table_info, include, except)
  
  where_clause = makeWhereClause(where)
  
  # Total rows
  total_rows = sqlQuery(channel,
                        paste0("SELECT COUNT(*) cnt FROM ", tableName, where_clause)
                        )
  total_count = total_rows[[1,1]]
  table_info[, "total_count"] = total_count
  
  # Loop over numeric columns
  for(column_name in getNumericColumns(table_info)) {
    
    # Compute SELECT aggregate statistics on each numeric column
    column_stats = sqlQuery(channel,
                            paste0("SELECT count(distinct\"", column_name,"\") as distinct_count, ",
                                   "       count(\"", column_name, "\") as not_null_count, ",
                                   "       min(\"", column_name,"\") as minimum, ",
                                   "       max(\"", column_name,"\") as maximum, ",
                                   "       avg(cast(\"", column_name,"\" as bigint)) as average, ",
                                   "       stddev(cast(\"", column_name,"\" as bigint)) as deviation ",
                                   "  FROM ", tableName, where_clause)
                            )
    column_idx = which(table_info$COLUMN_NAME == column_name)
   
    table_info[column_idx, "distinct_count"] = column_stats[[1,"distinct_count"]]
    table_info[column_idx, "not_null_count"] = column_stats[[1,"not_null_count"]]
    table_info[column_idx, "minimum"] = column_stats[[1,"minimum"]]
    table_info[column_idx, "maximum"] = column_stats[[1,"maximum"]]
    table_info[column_idx, "average"] = column_stats[[1,"average"]]
    table_info[column_idx, "deviation"] = column_stats[[1,"deviation"]]
    
    # compute 0,25,50,75,100 percentiles with SQL/MR approximate percentile function
    percentiles = sqlQuery(channel,
                           paste0("SELECT * FROM approxPercentileReduce(
                                   ON (
                                     SELECT * FROM approxPercentileMap(
                                       ON  ( SELECT * FROM " , tableName, where_clause, " ) ",
                                  " TARGET_COLUMN( '",column_name,"' )
                                       ERROR( 1 )
                                     )
                                   )
                                   PARTITION BY 1
                                   PERCENTILE( 0,10,25,50,75,90,100 ))")
                           )
  
    table_info[column_idx, "0%"] = percentiles[[which(percentiles$percentile==0),"value"]]
    table_info[column_idx, "10%"] = percentiles[[which(percentiles$percentile==10),"value"]]
    table_info[column_idx, "25%"] = percentiles[[which(percentiles$percentile==25),"value"]]
    table_info[column_idx, "50%"] = percentiles[[which(percentiles$percentile==50),"value"]]
    table_info[column_idx, "75%"] = percentiles[[which(percentiles$percentile==75),"value"]]
    table_info[column_idx, "90%"] = percentiles[[which(percentiles$percentile==90),"value"]]
    table_info[column_idx, "100%"] = percentiles[[which(percentiles$percentile==100),"value"]]
    table_info[column_idx, "IQR"] = percentiles[[which(percentiles$percentile==75),"value"]] -
      percentiles[[which(percentiles$percentile==25),"value"]]
  }
  
  # Loop over non-numeric columns 
  non_numeric_columns = c(getCharacterColumns(table_info),
                          getDateTimeColumns(table_info))
  for(column_name in non_numeric_columns) {
    column_stats = sqlQuery(channel,
                            paste0("SELECT count(distinct\"", column_name, "\") as distinct_count, ",
                                   "       count(\"", column_name, "\") as not_null_count, ",
                                   "       min(\"", column_name, "\") as minimum, ",
                                   "       max(\"", column_name, "\") as maximum ",
                                   "  FROM ", tableName, where_clause)
                            )
    column_idx = which(table_info$COLUMN_NAME == column_name)
    table_info[column_idx, "distinct_count"] = column_stats[[1,"distinct_count"]]
    table_info[column_idx, "not_null_count"] = column_stats[[1,"not_null_count"]]
    table_info[column_idx, "minimum"] = column_stats[[1,"minimum"]]
    table_info[column_idx, "maximum"] = column_stats[[1,"maximum"]]
  }
  
  # Collect modes
  if(collect.mode) {
    for(column_name in table_info$COLUMN_NAME) {
      mode = sqlQuery(channel,
                      paste0("SELECT \"", column_name, "\" val, count(*) cnt ",
                             "  FROM ", tableName, where_clause,
                             " GROUP BY 1 ORDER BY 2 DESC LIMIT 1")
                      )
      column_idx = which(table_info$COLUMN_NAME == column_name)
      table_info[column_idx, "mode"] = toString(mode[[1,"val"]])
      table_info[column_idx, "mode_count"] = mode[[1, "cnt"]]
    }
    
  }
  
  
  return(table_info)
    
}


#' computeCorrelations
#' Compute correlations between all or specified numeric columns in a table
#' @param connection object as returned by \code{\link{odbcConnect}}
#' @param tableName database table name
#' 
#' @export
computeCorrelations <- function(channel, tableName, include=NULL, except=NULL) {
  table_info = sqlColumns(channel, tableName)
  
  columns = getNumericColumns(table_info, names.only=TRUE, include=include, except=except)
  
  correlations = subset(expand.grid(columns, columns, stringsAsFactors = FALSE),
                        subset=Var1<Var2)
  correlations = apply(correlations, 1, function(x) paste(x, collapse=':'))
  
  sqlmr_correlations = paste(correlations, collapse="', '")
  
  rs_corrs = sqlQuery(channel, 
                paste0("SELECT * FROM corr_reduce(
                  on corr_map(
                    on ", tableName, 
                    " columnpairs( '", sqlmr_correlations, "')
                    key_name('key')
                  )
                  partition by key
                )"))
  
  rs_corrs = cbind(rs_corrs, t(sapply(rs_corrs$corr, 
         FUN=function(v) unlist(strsplit(toString(v), split=":")))))
  colnames(rs_corrs)[3] = 'metric1'
  colnames(rs_corrs)[4] = 'metric2'
  
  # make data frame symmetrical
  temp = rs_corrs
  temp[,c('metric1','metric2')] = rs_corrs[,c('metric2','metric1')]
  rs_corrs = rbind(rs_corrs, temp)
  
  # produce sign column
  signs = ifelse(sign(rs_corrs$value)>0, "1", ifelse(sign(rs_corrs$value)<0, "-1", "0"))
  rs_corrs$sign = factor(signs, levels=c("-1","0","1"), ordered=TRUE)
  
  return(rs_corrs)
}

#' Compute column histogram
#' 
#' @export
computeHistogram <- function(channel, tableName, columnName, 
                             binsize=NULL, startvalue=NULL, endvalue=NULL, numbins=NULL, 
                             where=NULL, by=NULL) {
  
  # compute histogram parameters if missing
  if (is.null(binsize) | is.null(startvalue) | is.null(endvalue)) {
    column_stats = getTableSummary(channel, tableName, include=columnName, where=where)
    IQR = column_stats[[1,"IQR"]]
    MIN = column_stats[[1,"minimum"]]
    MAX = column_stats[[1,"maximum"]]
    Q1 = column_stats[[1,"25%"]]
    Q3 = column_stats[[1,"75%"]]
    
    if (is.null(startvalue)) {
      startvalue = max(MIN, Q1-1.5*IQR)
    }
    
    if (is.null(endvalue)) {
      endvalue = min(MAX, Q3+1.5*IQR)
    }
    
    if (is.null(binsize)) {
      if (is.null(numbins)) {
        numbins = 30
      }
      binsize = (endvalue - startvalue) / numbins
    }
    
  }
  
  where_clause = makeWhereClause(where)
  
  # No by clause - single histogram
  if (is.null(by)) {
    histogram = sqlQuery(asterConn,
                       paste0("SELECT * 
                                 FROM hist_reduce(
                                        ON hist_map(
                                          ON (SELECT cast(\"", columnName, "\" as numeric) ", columnName, " FROM ", tableName, where_clause,
                                          "  ) 
                                          binsize('", binsize, "')
                                          startvalue('", startvalue, "')
                                          endvalue('", endvalue, "')
                                          value_column('", columnName, "')
                                        ) 
                                        partition by 1
                                      )")
                         
    )
  # By clause - multiple histograms for each value of 'by' attribute
  }else {
    
  }
  
  return(histogram)
}